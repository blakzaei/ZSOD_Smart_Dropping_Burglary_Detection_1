{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":216616615,"sourceType":"kernelVersion"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-- Install ultralytics for YOLO  --------------------------------------------------------------------------------\n!pip install ultralytics\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport ultralytics\nultralytics.checks()\n#---------------------------------------------------------------------------------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-26T06:13:19.824532Z","iopub.execute_input":"2025-01-26T06:13:19.824838Z","iopub.status.idle":"2025-01-26T06:13:29.302822Z","shell.execute_reply.started":"2025-01-26T06:13:19.824801Z","shell.execute_reply":"2025-01-26T06:13:29.302132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Import Libraries ---------------------------------------------------------------------------------\nimport os\nimport glob\nimport cv2\nimport numpy as np\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\nimport random\n#---------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T06:28:04.316778Z","iopub.execute_input":"2025-01-26T06:28:04.317112Z","iopub.status.idle":"2025-01-26T06:28:04.320917Z","shell.execute_reply.started":"2025-01-26T06:28:04.317082Z","shell.execute_reply":"2025-01-26T06:28:04.320031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Load Model -----------------------------------------------------------------------------------\nmodel = YOLO('yolo11x.pt')\n#---------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T06:13:33.811652Z","iopub.execute_input":"2025-01-26T06:13:33.811939Z","iopub.status.idle":"2025-01-26T06:13:35.232169Z","shell.execute_reply.started":"2025-01-26T06:13:33.811916Z","shell.execute_reply":"2025-01-26T06:13:35.231293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Function to Process video and save frame numbers with human -------------------------------------------\ndef process_video(video_file, output_dir):   \n   \n    \n    video_name = os.path.basename(video_file).split('.')[0]\n    output_file = os.path.join(output_dir, f\"{video_name}_human.npy\")\n\n    # Open the video file\n    cap = cv2.VideoCapture(video_file)\n    if not cap.isOpened():\n        print(f\"Error opening video file: {video_file}\")\n        return\n        \n\n    frame_list_with_humans = []\n    frame_number = 0\n\n    while True:\n        ret, frame = cap.read()  \n        if not ret:\n            break     \n\n        #-- Run YOLO model inference on the frame --\n        results = model.predict(frame, conf=0.5, verbose=False)\n\n        #-- Check if any person is detected in the frame --\n        human_found = False\n        for result in results:\n            for box in result.boxes:\n                if box.cls == 0:  #-- Class 0 is typically 'person' in YOLO models --\n                    frame_list_with_humans.append(frame_number)\n                    human_found = True\n                    break  #-- Break to avoid duplicate addition --\n                \n            if human_found:\n                break\n            \n        frame_number += 1\n\n    #-- Release the video capture object --\n    cap.release()\n\n    #-- Save the frame numbers as a NumPy array --\n    np.save(output_file, np.array(frame_list_with_humans))\n    print(f\"Processed {video_name}: {len(frame_list_with_humans)} frames with humans saved to {output_file}\")\n\n    return output_file\n#---------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T06:29:57.106700Z","iopub.execute_input":"2025-01-26T06:29:57.107021Z","iopub.status.idle":"2025-01-26T06:29:57.113396Z","shell.execute_reply.started":"2025-01-26T06:29:57.106998Z","shell.execute_reply":"2025-01-26T06:29:57.112494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Function to Check and Display frames include humans --------------------------------------------------\ndef display_random_detected_frames(video_path, frames_file, num_frames_to_show=10):\n    #-- Load the saved frame numbers --\n    detected_frames = np.load(frames_file)\n    print(f\"Loaded {len(detected_frames)} frames from {frames_file}\")\n\n    #-- If there are fewer frames than the number requested, adjust automatically --\n    if len(detected_frames) < num_frames_to_show:\n        num_frames_to_show = len(detected_frames)\n\n    #-- Select random frames to display --\n    random_frames = random.sample(list(detected_frames), num_frames_to_show)\n    print(f\"Randomly selected frames to display: {random_frames}\")\n    \n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Error opening video file: {video_path}\")\n        return\n\n    for frame_number in random_frames:\n        #-- Set the video to the specific frame --\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)  #-- Frame indices are 0-based\n\n        ret, frame = cap.read()\n        if not ret:\n            print(f\"Could not read frame {frame_number}\")\n            continue\n\n        #-- Convert the frame from BGR to RGB for matplotlib --\n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n        #-- Display the frame using matplotlib --\n        plt.figure(figsize=(10, 6))\n        plt.imshow(frame_rgb)\n        plt.title(f\"Frame {frame_number}\")\n        plt.axis('off')\n        plt.show()\n\n    \n    cap.release()\n#---------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T06:31:26.172025Z","iopub.execute_input":"2025-01-26T06:31:26.172416Z","iopub.status.idle":"2025-01-26T06:31:26.178804Z","shell.execute_reply.started":"2025-01-26T06:31:26.172383Z","shell.execute_reply":"2025-01-26T06:31:26.177736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Run on Burglary Samples ----------------------------------------------------------------------------\nburglary_samples_dir = \"/kaggle/input/novin-create-binary-burglary-ds/burglary_samples/\"  \nburglary_output_dir = \"burglary_samples\"  \n\nos.makedirs(burglary_output_dir, exist_ok=True)\n\nvideo_files = glob.glob(os.path.join(burglary_samples_dir, \"*.mp4\"))  \nprint(f'Number of Videos: {len(video_files)}')\n\nfor video_file in video_files:\n    frames_file = process_video(video_file, burglary_output_dir)\n    # display_random_detected_frames(video_file, frames_file, num_frames_to_show=5)\n    # break\n#---------------------------------------------------------------------------------------------------------------  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T06:26:28.706867Z","iopub.execute_input":"2025-01-26T06:26:28.707189Z","iopub.status.idle":"2025-01-26T06:26:40.724408Z","shell.execute_reply.started":"2025-01-26T06:26:28.707162Z","shell.execute_reply":"2025-01-26T06:26:40.723583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Run on Not Burglary Samples ----------------------------------------------------------------------------\nnot_burglary_samples_dir = \"/kaggle/input/novin-create-binary-burglary-ds/not_burglary_samples/\"  \nnot_burglary_output_dir = \"not_burglary_samples\"  \n\nos.makedirs(not_burglary_output_dir, exist_ok=True)\n\nvideo_files = glob.glob(os.path.join(not_burglary_samples_dir, \"*.mp4\"))  \nprint(f'Number of Videos: {len(video_files)}')\n\nfor video_file in video_files:\n    frames_file = process_video(video_file, not_burglary_output_dir)\n    # display_random_detected_frames(video_file, frames_file, num_frames_to_show=5)\n    # break\n#---------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T06:26:49.932398Z","iopub.execute_input":"2025-01-26T06:26:49.932698Z","iopub.status.idle":"2025-01-26T06:27:01.906238Z","shell.execute_reply.started":"2025-01-26T06:26:49.932675Z","shell.execute_reply":"2025-01-26T06:27:01.905303Z"}},"outputs":[],"execution_count":null}]}