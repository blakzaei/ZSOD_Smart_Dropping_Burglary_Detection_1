{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":216616615,"sourceType":"kernelVersion"},{"sourceId":218142975,"sourceType":"kernelVersion"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-- Burglary Detection\n#-- YOLO-World\n#-- SMART_Dropping: K-Means _With 32 key frames ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T06:53:48.144050Z","iopub.execute_input":"2025-01-19T06:53:48.144738Z","iopub.status.idle":"2025-01-19T06:53:48.148373Z","shell.execute_reply.started":"2025-01-19T06:53:48.144703Z","shell.execute_reply":"2025-01-19T06:53:48.147556Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#-- Install ultralytics for YOLO  --------------------------------------------------------------------------------\n!pip install ultralytics\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport ultralytics\nultralytics.checks()\n#---------------------------------------------------------------------------------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T06:53:58.745998Z","iopub.execute_input":"2025-01-19T06:53:58.746638Z","iopub.status.idle":"2025-01-19T06:54:07.575421Z","shell.execute_reply.started":"2025-01-19T06:53:58.746610Z","shell.execute_reply":"2025-01-19T06:54:07.574523Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.63 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete âœ… (4 CPUs, 31.4 GB RAM, 6095.9/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#-- Import libraries  ------------------------------------------------------------------------------------------\nfrom ultralytics import YOLO\nimport torch\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport csv\nimport random\n#---------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2025-01-19T06:54:10.212539Z","iopub.execute_input":"2025-01-19T06:54:10.212977Z","iopub.status.idle":"2025-01-19T06:54:10.499343Z","shell.execute_reply.started":"2025-01-19T06:54:10.212949Z","shell.execute_reply":"2025-01-19T06:54:10.498666Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#-- Initialize ---------------------------------------------------------------------------------------------------\nburglary_samples_dir = '/kaggle/input/novin-create-binary-burglary-ds/burglary_samples/'\nnot_burglary_samples_dir = '/kaggle/input/novin-create-binary-burglary-ds/not_burglary_samples/'\n\nkey_frames_burglary_samples_dir = '/kaggle/input/novin-smart-dropping-kmeans-clustering-v1/key_frames_burglary_samples/'\nkey_frames_not_burglary_samples_dir = '/kaggle/input/novin-smart-dropping-kmeans-clustering-v1/key_frames_not_burglary_samples/' \n\nCONF_THRESHOLD = 0.2\nIOU_THRESHOLD = 0.5\n\n#BRUGLARY_THRESHOLD_PERCENT = 0.1\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device:' , DEVICE)\n#---------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2025-01-19T06:58:23.450841Z","iopub.execute_input":"2025-01-19T06:58:23.451216Z","iopub.status.idle":"2025-01-19T06:58:23.456408Z","shell.execute_reply.started":"2025-01-19T06:58:23.451175Z","shell.execute_reply":"2025-01-19T06:58:23.455631Z"},"trusted":true},"outputs":[{"name":"stdout","text":"device: cuda\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#-- Get path for all videos and key_frames as a list ---------------------------------------------------------------------------\n#-- Burglary samples --\nburglary_videos = []\nfor dirpath, _, filenames in os.walk(burglary_samples_dir):\n    for filename in filenames:\n        full_path = os.path.join(dirpath, filename)\n        burglary_videos.append(full_path)\n\nburglary_key_frames = []\nfor dirpath, _, filenames in os.walk(key_frames_burglary_samples_dir):\n    for filename in filenames:\n        full_path = os.path.join(dirpath, filename)\n        burglary_key_frames.append(full_path)\n\n\n#-- Not Burglary Samples --\nnot_burglary_videos = []\nfor dirpath, _, filenames in os.walk(not_burglary_samples_dir):\n    for filename in filenames:\n        full_path = os.path.join(dirpath, filename)\n        not_burglary_videos.append(full_path)\n\nnot_urglary_key_frames = []\nfor dirpath, _, filenames in os.walk(key_frames_not_burglary_samples_dir):\n    for filename in filenames:\n        full_path = os.path.join(dirpath, filename)\n        not_urglary_key_frames.append(full_path)\n\nburglary_videos.sort()\nnot_burglary_videos.sort()\n\nprint(f'Burglary Samples: {len(burglary_videos)} - key-frames: {len(burglary_key_frames)}')\nprint(f'Not-Burglary Samples: {len(not_burglary_videos)}- key-frames: {len(burglary_key_frames)}')\n#---------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T07:02:20.141077Z","iopub.execute_input":"2025-01-19T07:02:20.141931Z","iopub.status.idle":"2025-01-19T07:02:20.268543Z","shell.execute_reply.started":"2025-01-19T07:02:20.141898Z","shell.execute_reply":"2025-01-19T07:02:20.267720Z"}},"outputs":[{"name":"stdout","text":"Burglary Samples: 34 - key-frames: 34\nNot-Burglary Samples: 34- key-frames: 34\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#-- Set label prompts for ZSOD Models ------------------------------------------------------------------------------------\nlabels = [\n    \"Person climbing over a fence\",\n    \"Person climbing a wall\",\n    \"Person breaking a lock with tools\",\n    \"Person trying to pick a lock\",\n    \"Person forcing a door open with strength\",          \n    \"Person hiding behind an object\",    \n    \"Person running away from a building\",\n    \"Person carrying tools like a crowbar\",\n    \"Person breaking a window with an object\",\n    \"Person tampering with a security camera\",\n    \"Person cutting alarm wires\",   \n    \"Person jumping out of a window\",\n    \"Person disabling an alarm system\",\n    \"Person wearing a mask and avoiding detection\"\n] \n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2025-01-19T07:02:26.367599Z","iopub.execute_input":"2025-01-19T07:02:26.367953Z","iopub.status.idle":"2025-01-19T07:02:26.373878Z","shell.execute_reply.started":"2025-01-19T07:02:26.367929Z","shell.execute_reply":"2025-01-19T07:02:26.372348Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#-- Create and Initialize Model ----------------------------------------------------------------------------------\n\n#-- YOLO World (Zero-Shot Model) --\nmodel_burglary_detection = YOLO('yolov8x-worldv2.pt')\nmodel_burglary_detection.set_classes(labels)\n\ndisplay.clear_output()\nprint('YOLO-world model was loaded successfully :)')\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2025-01-19T07:02:29.533490Z","iopub.execute_input":"2025-01-19T07:02:29.533824Z","iopub.status.idle":"2025-01-19T07:02:55.452051Z","shell.execute_reply.started":"2025-01-19T07:02:29.533799Z","shell.execute_reply":"2025-01-19T07:02:55.450935Z"},"trusted":true},"outputs":[{"name":"stdout","text":"YOLO-world model was loaded successfully :)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"#-- create an empty df for saving reults --------------------------------------------------------------------\ncolumns = [\"video_file\", \"true_label\", \"predicted_label\", \"all_detected_prompts\", \"burglary_threshold\"]\ndf_result = pd.DataFrame(columns=columns)\nprint(df_result.shape)\n#------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T07:03:02.587115Z","iopub.execute_input":"2025-01-19T07:03:02.587434Z","iopub.status.idle":"2025-01-19T07:03:02.593112Z","shell.execute_reply.started":"2025-01-19T07:03:02.587413Z","shell.execute_reply":"2025-01-19T07:03:02.592261Z"}},"outputs":[{"name":"stdout","text":"(0, 5)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"video_labels_dict = {}\nvideo_all_detections = {}\n\nfor video_path in burglary_videos:    \n\n    index = video_path.rfind('/')\n    video_file = video_path[index+1:]\n    index = video_file.rfind('.') \n    video_name = video_file[:index]    \n    \n    #-- log --\n    print(f'Processing {video_file} ==========================================================') \n\n    #-- Find corresponding key frame file --\n    key_frame_path = next((kf for kf in burglary_key_frames if video_name+'_keyframes.npy' in kf), None)\n    if key_frame_path is None:\n        print(f\"Key frame file not found for video {video_file}\")\n        continue\n\n    #-- Load key frames from .npy file --\n    key_frames = np.load(key_frame_path)  # Load the array of key frame indices\n    total_frames = len(key_frames)\n\n    #-- count number of detected prompts --\n    labels_count = {}\n    \n    for frame_idx in key_frames:  #-- Process only key frames\n        cap = cv2.VideoCapture(video_path)\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)  #-- Set video to the specific frame index\n        ret, frame = cap.read()\n        cap.release()\n\n        if not ret:\n            print(f\"Failed to read frame {frame_idx} from {video_file}\")\n            continue\n\n        \n        results = model_burglary_detection.predict(source=frame, \n                                                   conf=CONF_THRESHOLD,\n                                                   iou=IOU_THRESHOLD,\n                                                   show=False,\n                                                   save=False,\n                                                   stream=False)\n\n        for r in results:  # Process predictions\n            for cls_index in r.boxes.cls.int().tolist():\n                if labels[cls_index] in labels_count:\n                    labels_count[labels[cls_index]] += 1\n                else:\n                    labels_count[labels[cls_index]] = 1     \n\n    final_labels_list = []\n    all_detection_list = []\n    for cls_lbl, count in labels_count.items():\n        all_detection_list.append((cls_lbl, count))        \n        \n        # if count >= BRUGLARY_THRESHOLD:            \n        final_labels_list.append((cls_lbl, count))\n    \n    \n    video_labels_dict[video_file] = final_labels_list\n    video_all_detections[video_file] = all_detection_list\n\n    \n\n    \n    \n    \n    \ndisplay.clear_output()\nprint(':)')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T07:19:50.901368Z","iopub.execute_input":"2025-01-19T07:19:50.902035Z","iopub.status.idle":"2025-01-19T07:20:01.835092Z","shell.execute_reply.started":"2025-01-19T07:19:50.902008Z","shell.execute_reply":"2025-01-19T07:20:01.834247Z"}},"outputs":[{"name":"stdout","text":"Processing burglary_1.mp4 ==========================================================\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 2.7ms preprocess, 66.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 65.9ms\nSpeed: 3.1ms preprocess, 65.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 65.9ms\nSpeed: 2.5ms preprocess, 65.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 3.1ms preprocess, 66.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 2.3ms preprocess, 66.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 1 Person jumping out of a window, 66.0ms\nSpeed: 3.3ms preprocess, 66.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 2.3ms preprocess, 66.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 2.4ms preprocess, 66.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 1 Person climbing a wall, 65.9ms\nSpeed: 2.4ms preprocess, 65.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 3.0ms preprocess, 66.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 1 Person hiding behind an object, 65.3ms\nSpeed: 2.3ms preprocess, 65.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 59.8ms\nSpeed: 3.0ms preprocess, 59.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 59.4ms\nSpeed: 2.3ms preprocess, 59.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 1 Person climbing a wall, 59.4ms\nSpeed: 2.3ms preprocess, 59.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 59.5ms\nSpeed: 2.3ms preprocess, 59.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 2.5ms preprocess, 66.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.1ms\nSpeed: 2.5ms preprocess, 66.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 1 Person climbing a wall, 1 Person jumping out of a window, 66.0ms\nSpeed: 2.4ms preprocess, 66.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.1ms\nSpeed: 3.1ms preprocess, 66.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 65.9ms\nSpeed: 2.4ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 1 Person climbing a wall, 1 Person hiding behind an object, 1 Person tampering with a security camera, 66.1ms\nSpeed: 2.4ms preprocess, 66.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 1 Person climbing a wall, 65.9ms\nSpeed: 2.3ms preprocess, 65.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 1 Person climbing a wall, 66.1ms\nSpeed: 3.0ms preprocess, 66.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 65.9ms\nSpeed: 2.6ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 2.3ms preprocess, 66.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 1 Person climbing a wall, 66.2ms\nSpeed: 2.4ms preprocess, 66.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.1ms\nSpeed: 2.5ms preprocess, 66.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 3.1ms preprocess, 66.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 65.9ms\nSpeed: 2.3ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 2.4ms preprocess, 66.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 65.9ms\nSpeed: 2.4ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n\n0: 640x384 (no detections), 66.0ms\nSpeed: 2.3ms preprocess, 66.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"true_label = \"burglary\"\nfor video, lbls_list in video_all_detections.items():   \n    all_detected_prompts = lbls_list\n    if len(video_labels_dict[video]) > 0:\n        predicted_label = \"burglary\"\n    else:\n        predicted_label = \"not burglary\"\n    \n    df_result = pd.concat([df_result, pd.DataFrame([{\n        \"video_file\": video,\n        \"true_label\": true_label,\n        \"predicted_label\": predicted_label,\n        \"all_detected_prompts\": all_detected_prompts,\n        \"burglary_threshold\": '-' \n    }])], ignore_index=True)\n\nprint(df_result)\nprint(df_result.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T07:20:07.748517Z","iopub.execute_input":"2025-01-19T07:20:07.749332Z","iopub.status.idle":"2025-01-19T07:20:07.784306Z","shell.execute_reply.started":"2025-01-19T07:20:07.749303Z","shell.execute_reply":"2025-01-19T07:20:07.783446Z"}},"outputs":[{"name":"stdout","text":"       video_file true_label predicted_label  \\\n0  burglary_1.mp4   burglary        burglary   \n\n                                all_detected_prompts burglary_threshold  \n0  [(Person jumping out of a window, 2), (Person ...                  -  \n(1, 5)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"video_labels_dict = {}\nvideo_all_detections = {}\n\nfor video_path in not_burglary_videos:    \n\n    index = video_path.rfind('/')\n    video_file = video_path[index+1:]\n    index = video_file.rfind('.') \n    video_name = video_file[:index]    \n    \n    #-- log --\n    print(f'Processing {video_file} ==========================================================') \n\n    #-- Find corresponding key frame file --\n    key_frame_path = next((kf for kf in not_urglary_key_frames if video_name+'_keyframes.npy' in kf), None)\n    if key_frame_path is None:\n        print(f\"Key frame file not found for video {video_file}\")\n        continue\n\n    #-- Load key frames from .npy file --\n    key_frames = np.load(key_frame_path)  # Load the array of key frame indices\n    total_frames = len(key_frames)\n\n    #-- count number of detected prompts --\n    labels_count = {}\n    \n    for frame_idx in key_frames:  #-- Process only key frames\n        cap = cv2.VideoCapture(video_path)\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)  #-- Set video to the specific frame index\n        ret, frame = cap.read()\n        cap.release()\n\n        if not ret:\n            print(f\"Failed to read frame {frame_idx} from {video_file}\")\n            continue\n\n        \n        results = model_burglary_detection.predict(source=frame, \n                                                   conf=CONF_THRESHOLD,\n                                                   iou=IOU_THRESHOLD,\n                                                   show=False,\n                                                   save=False,\n                                                   stream=False)\n\n        for r in results:  # Process predictions\n            for cls_index in r.boxes.cls.int().tolist():\n                if labels[cls_index] in labels_count:\n                    labels_count[labels[cls_index]] += 1\n                else:\n                    labels_count[labels[cls_index]] = 1     \n\n    final_labels_list = []\n    all_detection_list = []\n    for cls_lbl, count in labels_count.items():\n        all_detection_list.append((cls_lbl, count))        \n        \n        # if count >= BRUGLARY_THRESHOLD:            \n        final_labels_list.append((cls_lbl, count))\n    \n    \n    video_labels_dict[video_file] = final_labels_list\n    video_all_detections[video_file] = all_detection_list\n\n    \n\n    \n    \n    \n    \ndisplay.clear_output()\nprint(':)')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T07:24:02.849002Z","iopub.execute_input":"2025-01-19T07:24:02.849688Z","iopub.status.idle":"2025-01-19T07:24:11.077389Z","shell.execute_reply.started":"2025-01-19T07:24:02.849658Z","shell.execute_reply":"2025-01-19T07:24:11.076358Z"}},"outputs":[{"name":"stdout","text":"Processing not_burglary_1.mp4 ==========================================================\n\n0: 480x640 (no detections), 78.5ms\nSpeed: 2.2ms preprocess, 78.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 77.8ms\nSpeed: 1.7ms preprocess, 77.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.9ms\nSpeed: 1.7ms preprocess, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 47.2ms\nSpeed: 2.3ms preprocess, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.9ms\nSpeed: 1.9ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 43.9ms\nSpeed: 1.7ms preprocess, 43.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 47.8ms\nSpeed: 1.7ms preprocess, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 43.8ms\nSpeed: 1.6ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 42.5ms\nSpeed: 1.8ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 48.4ms\nSpeed: 1.6ms preprocess, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.2ms\nSpeed: 1.6ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 47.5ms\nSpeed: 2.3ms preprocess, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 39.2ms\nSpeed: 1.7ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 42.4ms\nSpeed: 1.5ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 53.3ms\nSpeed: 1.6ms preprocess, 53.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 42.9ms\nSpeed: 2.3ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 43.8ms\nSpeed: 1.7ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.3ms\nSpeed: 1.8ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.6ms\nSpeed: 1.7ms preprocess, 44.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 49.4ms\nSpeed: 1.7ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.2ms\nSpeed: 1.7ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 42.1ms\nSpeed: 1.7ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.4ms\nSpeed: 2.3ms preprocess, 44.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 48.3ms\nSpeed: 1.5ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 40.5ms\nSpeed: 1.8ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 43.2ms\nSpeed: 1.6ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.9ms\nSpeed: 1.6ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.9ms\nSpeed: 2.2ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.7ms\nSpeed: 1.9ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.7ms\nSpeed: 2.3ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 41.6ms\nSpeed: 2.4ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 40.0ms\nSpeed: 1.7ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\nProcessing not_burglary_10.mp4 ==========================================================\n\n0: 480x640 (no detections), 37.0ms\nSpeed: 1.7ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 40.0ms\nSpeed: 2.4ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 43.4ms\nSpeed: 1.6ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 38.4ms\nSpeed: 1.8ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.4ms\nSpeed: 2.0ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.0ms\nSpeed: 2.4ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.6ms\nSpeed: 1.8ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.0ms\nSpeed: 1.7ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.6ms\nSpeed: 1.6ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.3ms\nSpeed: 1.9ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.9ms\nSpeed: 2.4ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.4ms\nSpeed: 1.8ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.0ms\nSpeed: 2.4ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.6ms\nSpeed: 2.0ms preprocess, 44.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.9ms\nSpeed: 2.0ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.4ms\nSpeed: 2.4ms preprocess, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.5ms\nSpeed: 2.3ms preprocess, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.9ms\nSpeed: 1.7ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 1 Person climbing a wall, 44.5ms\nSpeed: 2.3ms preprocess, 44.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.5ms\nSpeed: 2.4ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.9ms\nSpeed: 2.0ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.3ms\nSpeed: 1.8ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.8ms\nSpeed: 1.9ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 1 Person wearing a mask and avoiding detection, 44.9ms\nSpeed: 2.4ms preprocess, 44.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.4ms\nSpeed: 2.7ms preprocess, 45.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.0ms\nSpeed: 1.8ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.8ms\nSpeed: 1.7ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.2ms\nSpeed: 1.8ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.2ms\nSpeed: 2.3ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.4ms\nSpeed: 2.6ms preprocess, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.2ms\nSpeed: 2.3ms preprocess, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.7ms\nSpeed: 1.8ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\nProcessing not_burglary_11.mp4 ==========================================================\n\n0: 480x640 (no detections), 46.5ms\nSpeed: 2.4ms preprocess, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.7ms\nSpeed: 1.9ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.7ms\nSpeed: 1.7ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 44.4ms\nSpeed: 1.8ms preprocess, 44.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 43.9ms\nSpeed: 1.8ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.6ms\nSpeed: 1.6ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 46.7ms\nSpeed: 1.6ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 40.8ms\nSpeed: 1.7ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 45.0ms\nSpeed: 1.8ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 53.6ms\nSpeed: 1.7ms preprocess, 53.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 54.0ms\nSpeed: 2.3ms preprocess, 54.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 (no detections), 49.4ms\nSpeed: 1.7ms preprocess, 49.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_idx \u001b[38;5;129;01min\u001b[39;00m key_frames:  \u001b[38;5;66;03m#-- Process only key frames\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_idx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#-- Set video to the specific frame index\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     31\u001b[0m     cap\u001b[38;5;241m.\u001b[39mrelease()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":33},{"cell_type":"code","source":"true_label = \"not burglary\"\nfor video, lbls_list in video_all_detections.items():   \n    all_detected_prompts = lbls_list\n    if len(video_labels_dict[video]) > 0:\n        predicted_label = \"burglary\"\n    else:\n        predicted_label = \"not burglary\"\n    \n    df_result = pd.concat([df_result, pd.DataFrame([{\n        \"video_file\": video,\n        \"true_label\": true_label,\n        \"predicted_label\": predicted_label,\n        \"all_detected_prompts\": all_detected_prompts,\n        \"burglary_threshold\": '-'\n    }])], ignore_index=True)\n\nprint(df_result)\nprint(df_result.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T07:23:23.784679Z","iopub.execute_input":"2025-01-19T07:23:23.785007Z","iopub.status.idle":"2025-01-19T07:23:23.794596Z","shell.execute_reply.started":"2025-01-19T07:23:23.784983Z","shell.execute_reply":"2025-01-19T07:23:23.793779Z"}},"outputs":[{"name":"stdout","text":"           video_file    true_label predicted_label  \\\n0      burglary_1.mp4      burglary        burglary   \n1  not_burglary_1.mp4  not burglary    not burglary   \n\n                                all_detected_prompts burglary_threshold  \n0  [(Person jumping out of a window, 2), (Person ...                  -  \n1                                                 []                  -  \n(2, 5)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"df_result.to_csv('results.csv', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:37:07.708006Z","iopub.execute_input":"2025-01-08T08:37:07.708305Z","iopub.status.idle":"2025-01-08T08:37:07.716581Z","shell.execute_reply.started":"2025-01-08T08:37:07.708283Z","shell.execute_reply":"2025-01-08T08:37:07.715867Z"}},"outputs":[],"execution_count":null}]}